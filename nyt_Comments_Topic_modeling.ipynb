{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mrudulbanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6663: expected 34 fields, saw 36\\nSkipping line 8310: expected 34 fields, saw 45\\nSkipping line 12508: expected 34 fields, saw 36\\nSkipping line 15065: expected 34 fields, saw 39\\n'\n",
      "b'Skipping line 23129: expected 34 fields, saw 48\\nSkipping line 27382: expected 34 fields, saw 39\\nSkipping line 28634: expected 34 fields, saw 51\\n'\n",
      "b'Skipping line 36999: expected 34 fields, saw 42\\nSkipping line 38494: expected 34 fields, saw 40\\n'\n",
      "b'Skipping line 64238: expected 34 fields, saw 44\\n'\n",
      "b'Skipping line 67093: expected 34 fields, saw 36\\nSkipping line 75805: expected 34 fields, saw 47\\nSkipping line 78659: expected 34 fields, saw 36\\n'\n",
      "b'Skipping line 87316: expected 34 fields, saw 49\\nSkipping line 91457: expected 34 fields, saw 35\\nSkipping line 94435: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 99792: expected 34 fields, saw 57\\nSkipping line 103553: expected 34 fields, saw 44\\nSkipping line 107773: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 115771: expected 34 fields, saw 44\\nSkipping line 120094: expected 34 fields, saw 42\\nSkipping line 121651: expected 34 fields, saw 42\\nSkipping line 126933: expected 34 fields, saw 75\\n'\n",
      "b'Skipping line 131306: expected 34 fields, saw 49\\nSkipping line 132769: expected 34 fields, saw 42\\nSkipping line 134339: expected 34 fields, saw 42\\nSkipping line 142857: expected 34 fields, saw 62\\n'\n",
      "b'Skipping line 148517: expected 34 fields, saw 37\\nSkipping line 149980: expected 34 fields, saw 54\\nSkipping line 151425: expected 34 fields, saw 42\\nSkipping line 155660: expected 34 fields, saw 47\\nSkipping line 158511: expected 34 fields, saw 40\\nSkipping line 160032: expected 34 fields, saw 43\\n'\n",
      "b'Skipping line 165753: expected 34 fields, saw 39\\nSkipping line 168347: expected 34 fields, saw 35\\nSkipping line 175203: expected 34 fields, saw 47\\nSkipping line 176515: expected 34 fields, saw 40\\nSkipping line 178036: expected 34 fields, saw 44\\n'\n",
      "b'Skipping line 180653: expected 34 fields, saw 39\\nSkipping line 184716: expected 34 fields, saw 37\\nSkipping line 188651: expected 34 fields, saw 46\\nSkipping line 189873: expected 34 fields, saw 40\\nSkipping line 191272: expected 34 fields, saw 55\\n'\n",
      "b'Skipping line 198728: expected 34 fields, saw 37\\nSkipping line 200102: expected 34 fields, saw 47\\nSkipping line 202852: expected 34 fields, saw 45\\nSkipping line 206860: expected 34 fields, saw 37\\nSkipping line 209533: expected 34 fields, saw 41\\nSkipping line 210854: expected 34 fields, saw 35\\nSkipping line 212211: expected 34 fields, saw 59\\n'\n",
      "b'Skipping line 214781: expected 34 fields, saw 46\\nSkipping line 216320: expected 34 fields, saw 46\\nSkipping line 218872: expected 34 fields, saw 35\\nSkipping line 222551: expected 34 fields, saw 59\\nSkipping line 224933: expected 34 fields, saw 38\\nSkipping line 226132: expected 34 fields, saw 35\\nSkipping line 227443: expected 34 fields, saw 39\\nSkipping line 228770: expected 34 fields, saw 42\\n'\n",
      "b'Skipping line 234513: expected 34 fields, saw 37\\nSkipping line 235732: expected 34 fields, saw 37\\nSkipping line 242775: expected 34 fields, saw 59\\n'\n",
      "b'Skipping line 247450: expected 34 fields, saw 35\\nSkipping line 250646: expected 34 fields, saw 56\\nSkipping line 254229: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 268515: expected 34 fields, saw 36\\nSkipping line 271239: expected 34 fields, saw 48\\nSkipping line 272393: expected 34 fields, saw 36\\n'\n",
      "b'Skipping line 279478: expected 34 fields, saw 60\\nSkipping line 283991: expected 34 fields, saw 59\\nSkipping line 292489: expected 34 fields, saw 47\\nSkipping line 294865: expected 34 fields, saw 37\\n'\n",
      "b'Skipping line 296368: expected 34 fields, saw 36\\nSkipping line 297868: expected 34 fields, saw 42\\nSkipping line 300822: expected 34 fields, saw 41\\nSkipping line 304746: expected 34 fields, saw 42\\nSkipping line 305948: expected 34 fields, saw 39\\n'\n",
      "b'Skipping line 315676: expected 34 fields, saw 60\\nSkipping line 321083: expected 34 fields, saw 47\\nSkipping line 325235: expected 34 fields, saw 59\\n'\n",
      "b'Skipping line 335123: expected 34 fields, saw 48\\nSkipping line 336585: expected 34 fields, saw 45\\nSkipping line 339807: expected 34 fields, saw 42\\nSkipping line 343168: expected 34 fields, saw 64\\n'\n",
      "b'Skipping line 344444: expected 34 fields, saw 37\\nSkipping line 349454: expected 34 fields, saw 41\\nSkipping line 359082: expected 34 fields, saw 39\\n'\n",
      "b'Skipping line 362162: expected 34 fields, saw 69\\nSkipping line 366732: expected 34 fields, saw 36\\nSkipping line 368418: expected 34 fields, saw 58\\nSkipping line 373352: expected 34 fields, saw 53\\n'\n",
      "b'Skipping line 381413: expected 34 fields, saw 51\\nSkipping line 382690: expected 34 fields, saw 35\\nSkipping line 387492: expected 34 fields, saw 59\\n'\n",
      "b'Skipping line 394414: expected 34 fields, saw 63\\nSkipping line 396082: expected 34 fields, saw 37\\nSkipping line 397841: expected 34 fields, saw 49\\nSkipping line 402931: expected 34 fields, saw 39\\nSkipping line 406334: expected 34 fields, saw 40\\n'\n",
      "b'Skipping line 409913: expected 34 fields, saw 37\\nSkipping line 416636: expected 34 fields, saw 70\\n'\n",
      "C:\\Users\\mrudulbanka\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (0,2,4,5,8,9,10,11,13,14,15,17,18,19,20,21,23,25,26,27,29,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\mrudulbanka\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\mrudulbanka\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\mrudulbanka\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\mrudulbanka\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (14,15,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "b'Skipping line 3077: expected 34 fields, saw 35\\nSkipping line 15054: expected 34 fields, saw 64\\n'\n",
      "b'Skipping line 16598: expected 34 fields, saw 36\\nSkipping line 28104: expected 34 fields, saw 61\\n'\n",
      "b'Skipping line 42873: expected 34 fields, saw 47\\n'\n",
      "b'Skipping line 53694: expected 34 fields, saw 47\\nSkipping line 56533: expected 34 fields, saw 36\\nSkipping line 59323: expected 34 fields, saw 62\\nSkipping line 62533: expected 34 fields, saw 38\\nSkipping line 65255: expected 34 fields, saw 44\\n'\n",
      "b'Skipping line 66962: expected 34 fields, saw 36\\nSkipping line 71232: expected 34 fields, saw 62\\nSkipping line 80266: expected 34 fields, saw 63\\nSkipping line 81662: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 83072: expected 34 fields, saw 40\\nSkipping line 86080: expected 34 fields, saw 62\\nSkipping line 92966: expected 34 fields, saw 52\\n'\n",
      "b'Skipping line 103585: expected 34 fields, saw 47\\nSkipping line 111447: expected 34 fields, saw 60\\n'\n",
      "b'Skipping line 117253: expected 34 fields, saw 43\\nSkipping line 118589: expected 34 fields, saw 48\\nSkipping line 120355: expected 34 fields, saw 41\\nSkipping line 123418: expected 34 fields, saw 36\\nSkipping line 128327: expected 34 fields, saw 38\\n'\n",
      "b'Skipping line 146606: expected 34 fields, saw 63\\n'\n",
      "b'Skipping line 148363: expected 34 fields, saw 36\\nSkipping line 151496: expected 34 fields, saw 39\\nSkipping line 153253: expected 34 fields, saw 60\\nSkipping line 160248: expected 34 fields, saw 44\\nSkipping line 163375: expected 34 fields, saw 63\\n'\n",
      "b'Skipping line 170323: expected 34 fields, saw 44\\nSkipping line 172240: expected 34 fields, saw 39\\nSkipping line 175153: expected 34 fields, saw 35\\nSkipping line 176689: expected 34 fields, saw 48\\n'\n",
      "b'Skipping line 182785: expected 34 fields, saw 38\\nSkipping line 184430: expected 34 fields, saw 42\\nSkipping line 185996: expected 34 fields, saw 58\\nSkipping line 193713: expected 34 fields, saw 38\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 196651: expected 34 fields, saw 55\\nSkipping line 202072: expected 34 fields, saw 57\\nSkipping line 204869: expected 34 fields, saw 35\\nSkipping line 209237: expected 34 fields, saw 42\\nSkipping line 210715: expected 34 fields, saw 39\\n'\n",
      "b'Skipping line 213796: expected 34 fields, saw 36\\nSkipping line 219631: expected 34 fields, saw 45\\nSkipping line 220829: expected 34 fields, saw 62\\nSkipping line 222243: expected 34 fields, saw 43\\nSkipping line 229346: expected 34 fields, saw 37\\n'\n",
      "b'Skipping line 230803: expected 34 fields, saw 37\\nSkipping line 232360: expected 34 fields, saw 51\\nSkipping line 233850: expected 34 fields, saw 35\\nSkipping line 236867: expected 34 fields, saw 43\\nSkipping line 238178: expected 34 fields, saw 58\\nSkipping line 241414: expected 34 fields, saw 38\\nSkipping line 242951: expected 34 fields, saw 44\\n'\n",
      "b'Skipping line 246024: expected 34 fields, saw 37\\nSkipping line 253314: expected 34 fields, saw 43\\nSkipping line 256300: expected 34 fields, saw 50\\nSkipping line 257757: expected 34 fields, saw 38\\n'\n",
      "b'Skipping line 262394: expected 34 fields, saw 43\\nSkipping line 263827: expected 34 fields, saw 37\\nSkipping line 265412: expected 34 fields, saw 43\\nSkipping line 268064: expected 34 fields, saw 36\\nSkipping line 271184: expected 34 fields, saw 48\\nSkipping line 272636: expected 34 fields, saw 36\\nSkipping line 274344: expected 34 fields, saw 35\\nSkipping line 276011: expected 34 fields, saw 44\\n'\n",
      "b'Skipping line 281630: expected 34 fields, saw 44\\nSkipping line 289024: expected 34 fields, saw 47\\nSkipping line 290438: expected 34 fields, saw 53\\n'\n",
      "b'Skipping line 299089: expected 34 fields, saw 62\\nSkipping line 302087: expected 34 fields, saw 36\\nSkipping line 303795: expected 34 fields, saw 37\\nSkipping line 306788: expected 34 fields, saw 44\\n'\n",
      "b'Skipping line 317181: expected 34 fields, saw 40\\nSkipping line 318641: expected 34 fields, saw 57\\nSkipping line 324674: expected 34 fields, saw 36\\n'\n",
      "b'Skipping line 330667: expected 34 fields, saw 40\\nSkipping line 335288: expected 34 fields, saw 62\\nSkipping line 343159: expected 34 fields, saw 36\\n'\n",
      "b'Skipping line 344565: expected 34 fields, saw 35\\nSkipping line 354964: expected 34 fields, saw 47\\nSkipping line 358800: expected 34 fields, saw 42\\nSkipping line 360260: expected 34 fields, saw 55\\n'\n",
      "b'Skipping line 363530: expected 34 fields, saw 39\\nSkipping line 364932: expected 34 fields, saw 36\\nSkipping line 367755: expected 34 fields, saw 40\\nSkipping line 372423: expected 34 fields, saw 44\\nSkipping line 373882: expected 34 fields, saw 40\\nSkipping line 375461: expected 34 fields, saw 55\\n'\n",
      "b'Skipping line 377057: expected 34 fields, saw 38\\nSkipping line 380033: expected 34 fields, saw 36\\nSkipping line 391175: expected 34 fields, saw 40\\nSkipping line 392647: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 400960: expected 34 fields, saw 65\\nSkipping line 404192: expected 34 fields, saw 44\\nSkipping line 407977: expected 34 fields, saw 38\\n'\n",
      "b'Skipping line 413646: expected 34 fields, saw 39\\nSkipping line 416459: expected 34 fields, saw 46\\nSkipping line 419614: expected 34 fields, saw 58\\n'\n",
      "b'Skipping line 427180: expected 34 fields, saw 47\\nSkipping line 431834: expected 34 fields, saw 42\\nSkipping line 433433: expected 34 fields, saw 62\\nSkipping line 436401: expected 34 fields, saw 69\\nSkipping line 437873: expected 34 fields, saw 38\\nSkipping line 442307: expected 34 fields, saw 44\\n'\n",
      "b'Skipping line 443804: expected 34 fields, saw 53\\nSkipping line 445103: expected 34 fields, saw 35\\nSkipping line 451030: expected 34 fields, saw 55\\n'\n",
      "b'Skipping line 459805: expected 34 fields, saw 43\\nSkipping line 461304: expected 34 fields, saw 38\\nSkipping line 462903: expected 34 fields, saw 59\\nSkipping line 465472: expected 34 fields, saw 39\\nSkipping line 466985: expected 34 fields, saw 52\\nSkipping line 470089: expected 34 fields, saw 47\\nSkipping line 471386: expected 34 fields, saw 40\\n'\n",
      "b'Skipping line 477283: expected 34 fields, saw 36\\nSkipping line 478809: expected 34 fields, saw 42\\nSkipping line 480408: expected 34 fields, saw 62\\nSkipping line 483238: expected 34 fields, saw 55\\nSkipping line 489100: expected 34 fields, saw 40\\n'\n",
      "C:\\Users\\mrudulbanka\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (0,2,4,5,8,9,10,11,13,17,18,19,20,21,23,25,26,28,30,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"CommentsJan2017.csv\", error_bad_lines=False)\n",
    "df2 = pd.read_csv(\"CommentsFeb2017.csv\", error_bad_lines=False)\n",
    "df3 = pd.read_csv(\"CommentsMarch2017.csv\", error_bad_lines=False)\n",
    "df4 = pd.read_csv(\"CommentsApril2017.csv\", error_bad_lines=False)\n",
    "df5 = pd.read_csv(\"CommentsMay2017.csv\", error_bad_lines=False)\n",
    "df6 = pd.read_csv(\"CommentsJan2018.csv\", error_bad_lines=False)\n",
    "df7 = pd.read_csv(\"CommentsFeb2018.csv\", error_bad_lines=False)\n",
    "df8 = pd.read_csv(\"CommentsMarch2018.csv\", error_bad_lines=False)\n",
    "df9 = pd.read_csv(\"CommentsApril2018.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2653939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrudulbanka\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_text = df[['commentBody']]\n",
    "df_text['index'] = df_text.index\n",
    "documents = df_text\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2653938\n",
      "                                          commentBody  index\n",
      "0   For all you Americans out there --- still rejo...      0\n",
      "1   Obamas policies may prove to be the least of t...      1\n",
      "2   Democrats are comprised of malcontents who gen...      2\n",
      "3   The picture in this article is the face of con...      3\n",
      "4                        Elections have consequences.      4\n",
      "5    Shakespeare showed us that  appetite brings  ...      5\n",
      "6   \"Obama Policies Are in Peril as New Congress T...      6\n",
      "7   I'm glad to hear the Republicans are chomping ...      7\n",
      "8                     A typical Banana Republic deal.      8\n",
      "9   Well, Mitch you haven't done anything for eigh...      9\n",
      "10  Politics. What is it? …to Gain and maintain Po...     10\n",
      "11  I am retired and medicare is an absolutely ess...     11\n",
      "12  “It’s a big job to actually have responsibilit...     12\n",
      "13  One small ray of light in the GOP having full ...     13\n",
      "14  Repeal Obamacare.  There are too many people g...     14\n",
      "15  Well, maybe if Obama hadn't made that infernal...     15\n",
      "16  I will not shed a tear if some of the Obama po...     16\n",
      "17  Why do I always think of a tortoise when McCon...     17\n",
      "18   It would be nice if we could have a return to...     18\n",
      "19  I do not understand why the Senate's refusal t...     19\n",
      "20  Where I live, we were one of the hardest hit a...     20\n",
      "21  We are once again at the front line of whats g...     21\n",
      "22  You consider equality social ills, perhaps in ...     22\n",
      "23  They should just repeal Obamacare, re-enact it...     23\n",
      "24  '...“I hear probably more about the strangulat...     24\n",
      "25  \"This is no time for hubris.  You have to perf...     25\n",
      "26  Enough of the 30,000 foot analysis.  <br/><br/...     26\n",
      "27               Repeal and replace Obamacare Please!     27\n",
      "28  Given that senator Mitch McConnell's face is t...     28\n",
      "29  The Obama regime represented eight years of so...     29\n",
      "30  It would be interesting to see a pair of walls...     30\n",
      "31  I agree that McConnel failed to do his job by ...     31\n",
      "32  Equal rights will inevitably be set back by de...     32\n",
      "33  Lets be honest here and now.<br/>Even die hard...     33\n",
      "34                           Oh, the impotent tears!      34\n",
      "35  For all those who think Obamacare is great. Ye...     35\n",
      "36  I'm an Obama supporter. As painful as it is fo...     36\n",
      "37  \"Obama’s Policies Are in Peril\",news flash the...     37\n",
      "38  Looking at the U.S. budget, it is not too far ...     38\n",
      "39  No; \"Foolish\" pride is NOT prudent but is less...     39\n",
      "40  It's time for Mitch to retire to the elephants...     40\n",
      "41  Let's be clear - the GOP does believe in a gov...     41\n",
      "42  4 or 5 or 10 million people flooding into Wash...     42\n",
      "43  I get it that the motivation behind the ACA, \"...     43\n",
      "44  It's always funny how quickly politicians swit...     44\n",
      "45  Regrets are filing in via Twitter via his own ...     45\n",
      "46                     Obstruct, obstruct, obstruct!      46\n",
      "47  Why is it; writers, analysts, and such are scr...     47\n",
      "48  What will the Republicans replace Obama care w...     48\n",
      "49  Amusing, but sad, to read comments like this:<...     49\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Removing stopwords and words with length < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Republicans', 'are', 'about', 'to', 'replace', 'The', 'Affordable', 'Care', 'Act', '', 'with:<br/>The', 'Deplorable', 'Care', 'Act', '(GOPCare).', '', '', 'Run', 'with', 'it,', 'Archie', 'Bunker', 'voters.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['republican', 'replac', 'afford', 'care', 'deplor', 'care', 'gopcar', 'archi', 'bunker', 'voter']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [american, rejoic, major, republican, legislat...\n",
       "1    [obama, polici, prove, countri, worri, embolde...\n",
       "2    [democrat, compris, malcont, general, work, li...\n",
       "3    [pictur, articl, face, congression, leadership...\n",
       "4                                     [elect, consequ]\n",
       "5    [shakespear, show, appetit, bring, reveng, amb...\n",
       "6    [obama, polici, peril, congress, take, good, day]\n",
       "7    [glad, hear, republican, chomp, pass, republic...\n",
       "8                        [typic, banana, republ, deal]\n",
       "9                           [mitch, haven, year, rest]\n",
       "Name: commentBody, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['commentBody'].astype(str).map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words on the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 america\n",
      "1 american\n",
      "2 balanc\n",
      "3 belong\n",
      "4 bewar\n",
      "5 check\n",
      "6 constitut\n",
      "7 countri\n",
      "8 execut\n",
      "9 father\n",
      "10 form\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 1),\n",
       " (220, 2),\n",
       " (507, 1),\n",
       " (539, 1),\n",
       " (660, 1),\n",
       " (960, 1),\n",
       " (4681, 1),\n",
       " (4683, 1),\n",
       " (10277, 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 32 (\"republican\") appears 1 time.\n",
      "Word 220 (\"care\") appears 2 time.\n",
      "Word 507 (\"afford\") appears 1 time.\n",
      "Word 539 (\"replac\") appears 1 time.\n",
      "Word 660 (\"voter\") appears 1 time.\n",
      "Word 960 (\"deplor\") appears 1 time.\n",
      "Word 4681 (\"archi\") appears 1 time.\n",
      "Word 4683 (\"bunker\") appears 1 time.\n",
      "Word 10277 (\"gopcar\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.10235580792261652),\n",
      " (1, 0.08318612925863489),\n",
      " (2, 0.1667943666976924),\n",
      " (3, 0.19019785791497),\n",
      " (4, 0.24496263482815764),\n",
      " (5, 0.1492184126997314),\n",
      " (6, 0.13950929761444208),\n",
      " (7, 0.08177061829688986),\n",
      " (8, 0.15369949744962902),\n",
      " (9, 0.15964393829101606),\n",
      " (10, 0.14970854476304846),\n",
      " (11, 0.1986796821720344),\n",
      " (12, 0.10488617173704651),\n",
      " (13, 0.12434626284300544),\n",
      " (14, 0.10644646137159643),\n",
      " (15, 0.32908200838871193),\n",
      " (16, 0.14341875702417037),\n",
      " (17, 0.1302135728917596),\n",
      " (18, 0.15778904732243487),\n",
      " (19, 0.15550801986404453),\n",
      " (20, 0.21179114511529476),\n",
      " (21, 0.12363613582440229),\n",
      " (22, 0.3646141999938172),\n",
      " (23, 0.12610456258776748),\n",
      " (24, 0.10052053372071869),\n",
      " (25, 0.15175070997914514),\n",
      " (26, 0.10510281279822775),\n",
      " (27, 0.05965255187586534),\n",
      " (28, 0.09918280953265271),\n",
      " (29, 0.10562899566308456),\n",
      " (30, 0.27849021024336157),\n",
      " (31, 0.26324223069488173),\n",
      " (32, 0.08379730351864154),\n",
      " (33, 0.08244807329540045),\n",
      " (34, 0.16764103749300913)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA USING BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.019*\"peopl\" + 0.016*\"white\" + 0.013*\"right\" + 0.009*\"polit\" + 0.009*\"black\" + 0.008*\"liber\" + 0.008*\"think\" + 0.007*\"american\" + 0.007*\"like\" + 0.006*\"support\"\n",
      "Topic: 1 \n",
      "Words: 0.060*\"school\" + 0.038*\"https\" + 0.027*\"student\" + 0.027*\"target\" + 0.025*\"educ\" + 0.022*\"titl\" + 0.021*\"teacher\" + 0.021*\"colleg\" + 0.018*\"href\" + 0.016*\"pruitt\"\n",
      "Topic: 2 \n",
      "Words: 0.113*\"trump\" + 0.017*\"presid\" + 0.017*\"like\" + 0.016*\"know\" + 0.014*\"think\" + 0.011*\"say\" + 0.009*\"donald\" + 0.008*\"lie\" + 0.008*\"want\" + 0.008*\"go\"\n",
      "Topic: 3 \n",
      "Words: 0.041*\"republican\" + 0.029*\"vote\" + 0.027*\"democrat\" + 0.021*\"parti\" + 0.018*\"elect\" + 0.017*\"state\" + 0.013*\"congress\" + 0.013*\"justic\" + 0.012*\"court\" + 0.012*\"trump\"\n",
      "Topic: 4 \n",
      "Words: 0.013*\"countri\" + 0.013*\"israel\" + 0.011*\"korea\" + 0.011*\"peopl\" + 0.010*\"north\" + 0.010*\"state\" + 0.009*\"militari\" + 0.009*\"kill\" + 0.009*\"polic\" + 0.008*\"immigr\"\n",
      "Topic: 5 \n",
      "Words: 0.015*\"money\" + 0.011*\"work\" + 0.009*\"peopl\" + 0.008*\"compani\" + 0.008*\"cost\" + 0.008*\"need\" + 0.008*\"pay\" + 0.007*\"year\" + 0.007*\"govern\" + 0.007*\"busi\"\n",
      "Topic: 6 \n",
      "Words: 0.016*\"news\" + 0.016*\"question\" + 0.014*\"mueller\" + 0.013*\"investig\" + 0.011*\"time\" + 0.011*\"report\" + 0.010*\"comey\" + 0.009*\"media\" + 0.009*\"evid\" + 0.008*\"fact\"\n",
      "Topic: 7 \n",
      "Words: 0.013*\"women\" + 0.012*\"peopl\" + 0.010*\"life\" + 0.009*\"think\" + 0.009*\"know\" + 0.009*\"like\" + 0.008*\"time\" + 0.007*\"need\" + 0.007*\"work\" + 0.007*\"year\"\n",
      "Topic: 8 \n",
      "Words: 0.016*\"like\" + 0.011*\"look\" + 0.010*\"time\" + 0.009*\"think\" + 0.008*\"go\" + 0.007*\"year\" + 0.006*\"peopl\" + 0.005*\"come\" + 0.005*\"know\" + 0.005*\"watch\"\n",
      "Topic: 9 \n",
      "Words: 0.017*\"trump\" + 0.016*\"presid\" + 0.013*\"countri\" + 0.012*\"world\" + 0.010*\"america\" + 0.010*\"american\" + 0.008*\"nation\" + 0.008*\"power\" + 0.008*\"obama\" + 0.007*\"histori\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.011*\"nobel\" + 0.010*\"prize\" + 0.006*\"yeah\" + 0.006*\"marx\" + 0.005*\"peninsula\" + 0.005*\"nail\" + 0.005*\"funni\" + 0.005*\"win\" + 0.005*\"memo\" + 0.005*\"excel\"\n",
      "Topic: 1 Word: 0.007*\"thank\" + 0.006*\"trump\" + 0.005*\"think\" + 0.004*\"peopl\" + 0.004*\"good\" + 0.004*\"like\" + 0.003*\"presid\" + 0.003*\"comment\" + 0.003*\"read\" + 0.003*\"know\"\n",
      "Topic: 2 Word: 0.006*\"money\" + 0.004*\"compani\" + 0.004*\"work\" + 0.004*\"china\" + 0.004*\"tax\" + 0.004*\"peopl\" + 0.004*\"trade\" + 0.004*\"pay\" + 0.003*\"market\" + 0.003*\"busi\"\n",
      "Topic: 3 Word: 0.009*\"trump\" + 0.007*\"korea\" + 0.005*\"putin\" + 0.005*\"north\" + 0.005*\"china\" + 0.005*\"russia\" + 0.005*\"iran\" + 0.004*\"syria\" + 0.004*\"israel\" + 0.004*\"presid\"\n",
      "Topic: 4 Word: 0.012*\"vote\" + 0.010*\"republican\" + 0.010*\"democrat\" + 0.008*\"parti\" + 0.008*\"trump\" + 0.007*\"elect\" + 0.005*\"voter\" + 0.005*\"presid\" + 0.005*\"ryan\" + 0.004*\"candid\"\n",
      "Topic: 5 Word: 0.016*\"cosbi\" + 0.013*\"pruitt\" + 0.008*\"haley\" + 0.007*\"jackson\" + 0.006*\"daca\" + 0.006*\"scott\" + 0.005*\"simpson\" + 0.004*\"barbara\" + 0.004*\"nikki\" + 0.004*\"barr\"\n",
      "Topic: 6 Word: 0.007*\"school\" + 0.005*\"parent\" + 0.004*\"year\" + 0.004*\"children\" + 0.004*\"student\" + 0.004*\"life\" + 0.004*\"teacher\" + 0.004*\"peopl\" + 0.004*\"work\" + 0.004*\"kid\"\n",
      "Topic: 7 Word: 0.005*\"peopl\" + 0.005*\"white\" + 0.005*\"right\" + 0.004*\"black\" + 0.004*\"gun\" + 0.004*\"women\" + 0.003*\"polic\" + 0.003*\"countri\" + 0.003*\"american\" + 0.003*\"immigr\"\n",
      "Topic: 8 Word: 0.009*\"https\" + 0.005*\"watch\" + 0.005*\"like\" + 0.005*\"look\" + 0.005*\"time\" + 0.004*\"think\" + 0.004*\"read\" + 0.004*\"titl\" + 0.004*\"articl\" + 0.004*\"love\"\n",
      "Topic: 9 Word: 0.014*\"mueller\" + 0.013*\"trump\" + 0.008*\"question\" + 0.008*\"investig\" + 0.007*\"cohen\" + 0.007*\"comey\" + 0.005*\"lawyer\" + 0.005*\"leak\" + 0.005*\"presid\" + 0.005*\"know\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4310    [republican, replac, afford, care, deplor, car...\n",
       "4310    [object, need, support, american, citizen, ins...\n",
       "4310    [agre, easili, dupe, believ, trump, read, spee...\n",
       "4310    [hate, quot, clich, einstein, definit, insan, ...\n",
       "4310    [exact, right, progress, want, protest, better...\n",
       "4310    [stomach, plan, subject, hate, diatrib, lie, b...\n",
       "4310    [convolut, treacher, situat, courtesi, trumpis...\n",
       "4310                  [steel, manufactur, bonehead, lead]\n",
       "4310         [column, express, need, feder, control, law]\n",
       "Name: commentBody, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.37579602003097534\t \n",
      "Topic: 0.019*\"peopl\" + 0.016*\"white\" + 0.013*\"right\" + 0.009*\"polit\" + 0.009*\"black\" + 0.008*\"liber\" + 0.008*\"think\" + 0.007*\"american\" + 0.007*\"like\" + 0.006*\"support\"\n",
      "\n",
      "Score: 0.29278892278671265\t \n",
      "Topic: 0.015*\"money\" + 0.011*\"work\" + 0.009*\"peopl\" + 0.008*\"compani\" + 0.008*\"cost\" + 0.008*\"need\" + 0.008*\"pay\" + 0.007*\"year\" + 0.007*\"govern\" + 0.007*\"busi\"\n",
      "\n",
      "Score: 0.2613584101200104\t \n",
      "Topic: 0.041*\"republican\" + 0.029*\"vote\" + 0.027*\"democrat\" + 0.021*\"parti\" + 0.018*\"elect\" + 0.017*\"state\" + 0.013*\"congress\" + 0.013*\"justic\" + 0.012*\"court\" + 0.012*\"trump\"\n",
      "\n",
      "Score: 0.01000984851270914\t \n",
      "Topic: 0.113*\"trump\" + 0.017*\"presid\" + 0.017*\"like\" + 0.016*\"know\" + 0.014*\"think\" + 0.011*\"say\" + 0.009*\"donald\" + 0.008*\"lie\" + 0.008*\"want\" + 0.008*\"go\"\n",
      "\n",
      "Score: 0.010008752346038818\t \n",
      "Topic: 0.013*\"women\" + 0.012*\"peopl\" + 0.010*\"life\" + 0.009*\"think\" + 0.009*\"know\" + 0.009*\"like\" + 0.008*\"time\" + 0.007*\"need\" + 0.007*\"work\" + 0.007*\"year\"\n",
      "\n",
      "Score: 0.0100080082193017\t \n",
      "Topic: 0.017*\"trump\" + 0.016*\"presid\" + 0.013*\"countri\" + 0.012*\"world\" + 0.010*\"america\" + 0.010*\"american\" + 0.008*\"nation\" + 0.008*\"power\" + 0.008*\"obama\" + 0.007*\"histori\"\n",
      "\n",
      "Score: 0.010007944889366627\t \n",
      "Topic: 0.016*\"like\" + 0.011*\"look\" + 0.010*\"time\" + 0.009*\"think\" + 0.008*\"go\" + 0.007*\"year\" + 0.006*\"peopl\" + 0.005*\"come\" + 0.005*\"know\" + 0.005*\"watch\"\n",
      "\n",
      "Score: 0.010007374919950962\t \n",
      "Topic: 0.013*\"countri\" + 0.013*\"israel\" + 0.011*\"korea\" + 0.011*\"peopl\" + 0.010*\"north\" + 0.010*\"state\" + 0.009*\"militari\" + 0.009*\"kill\" + 0.009*\"polic\" + 0.008*\"immigr\"\n",
      "\n",
      "Score: 0.010007362812757492\t \n",
      "Topic: 0.016*\"news\" + 0.016*\"question\" + 0.014*\"mueller\" + 0.013*\"investig\" + 0.011*\"time\" + 0.011*\"report\" + 0.010*\"comey\" + 0.009*\"media\" + 0.009*\"evid\" + 0.008*\"fact\"\n",
      "\n",
      "Score: 0.01000735629349947\t \n",
      "Topic: 0.060*\"school\" + 0.038*\"https\" + 0.027*\"student\" + 0.027*\"target\" + 0.025*\"educ\" + 0.022*\"titl\" + 0.021*\"teacher\" + 0.021*\"colleg\" + 0.018*\"href\" + 0.016*\"pruitt\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5226225256919861\t Topic: 0.013*\"countri\" + 0.013*\"israel\" + 0.011*\"korea\" + 0.011*\"peopl\" + 0.010*\"north\"\n",
      "Score: 0.2773645222187042\t Topic: 0.060*\"school\" + 0.038*\"https\" + 0.027*\"student\" + 0.027*\"target\" + 0.025*\"educ\"\n",
      "Score: 0.02500499226152897\t Topic: 0.017*\"trump\" + 0.016*\"presid\" + 0.013*\"countri\" + 0.012*\"world\" + 0.010*\"america\"\n",
      "Score: 0.025001974776387215\t Topic: 0.015*\"money\" + 0.011*\"work\" + 0.009*\"peopl\" + 0.008*\"compani\" + 0.008*\"cost\"\n",
      "Score: 0.02500164322555065\t Topic: 0.041*\"republican\" + 0.029*\"vote\" + 0.027*\"democrat\" + 0.021*\"parti\" + 0.018*\"elect\"\n",
      "Score: 0.025001484900712967\t Topic: 0.019*\"peopl\" + 0.016*\"white\" + 0.013*\"right\" + 0.009*\"polit\" + 0.009*\"black\"\n",
      "Score: 0.02500098943710327\t Topic: 0.113*\"trump\" + 0.017*\"presid\" + 0.017*\"like\" + 0.016*\"know\" + 0.014*\"think\"\n",
      "Score: 0.025000913068652153\t Topic: 0.016*\"like\" + 0.011*\"look\" + 0.010*\"time\" + 0.009*\"think\" + 0.008*\"go\"\n",
      "Score: 0.025000544264912605\t Topic: 0.013*\"women\" + 0.012*\"peopl\" + 0.010*\"life\" + 0.009*\"think\" + 0.009*\"know\"\n",
      "Score: 0.025000423192977905\t Topic: 0.016*\"news\" + 0.016*\"question\" + 0.014*\"mueller\" + 0.013*\"investig\" + 0.011*\"time\"\n"
     ]
    }
   ],
   "source": [
    "# unseen_document = \"how should Facebook go about protecting its data and empowering user's data privacy rights\"\n",
    "unseen_document = \"school shootings all over the country\"\n",
    "\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
